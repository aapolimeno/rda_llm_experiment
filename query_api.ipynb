{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API access \n",
    "API keys are acquired from Perplexity Pro.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import random\n",
    "from datetime import datetime\n",
    "from api_keys import api_key\n",
    "\n",
    "\n",
    "# Function to make API call and get LLM response\n",
    "def get_llm_response(prompt, model):\n",
    "\n",
    "    \"\"\"\n",
    "    Make API call to get response from LLM\n",
    "    :param prompt: str: User query\n",
    "    :param model: str: Model name\n",
    "    :return: str: Answer from LLM\n",
    "    \"\"\"\n",
    "\n",
    "    if model == \"mistral-small\": \n",
    "        api_key = api_key\n",
    "        api_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "\n",
    "    \n",
    "    else: \n",
    "        api_key = api_key\n",
    "        api_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "\n",
    "    headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"accept\" : \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "    \"model\": f\"{model}\",  \n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful information retrieval assistant\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "    ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        answer = response.json()['choices'][0]['message']['content']\n",
    "        answer = answer.replace('\\n', ' ').replace('\\r\\n', ' ')\n",
    "        finish_reason = response.json()['choices'][0]['finish_reason']\n",
    "        \n",
    "    except KeyError: \n",
    "        answer = response.text\n",
    "        finish_reason = \"error\"\n",
    "\n",
    "\n",
    "    # Generate lodAIC\n",
    "    random_number = random.randint(0, 4294967295)\n",
    "    lodAIC = f\"pid_graph:AP{random_number:08X}\"\n",
    "\n",
    "\n",
    "    return answer, finish_reason, lodAIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write data to CSV\n",
    "def write_to_csv(data, filename):\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)\n",
    "\n",
    "# Main script\n",
    "csv_filename = \"llm_responses.csv\"\n",
    "\n",
    "# Write header if the file doesn't exist\n",
    "try:\n",
    "    with open(csv_filename, 'x', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"lodAIC\", \"Model\", \"Prompt\", \"Answer\", \"Date\", \"Finish Reason\"])\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"Identifier.csv\")\n",
    "pids = df[\"Title\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(pid, prop): \n",
    "\n",
    "    if prop == \"metadata\": \n",
    "        prompt = f\"\"\" \n",
    "        **Instruction**:  \n",
    "        You are an information retrieval assistant. Given a Persistent Identifier (PID), determine its metadata schema rules using registry documentation and known patterns. Choose from:  \n",
    "        1. **No Metadata Schema Prescribed** (No enforced schema)  \n",
    "        2. **Common Metadata Schema for Identifier** (Standardized schema for all instances)  \n",
    "        3. **Metadata Schema per Entity** (Class-specific schemas for different entities)  \n",
    "        4. **Custom/Non-Standard Metadata Schema** (No restrictions on schema structure)  \n",
    "        5. **Unknown** (insufficient information)  \n",
    "\n",
    "        **Desired Format**:  \n",
    "        <PID>: <structure category>, <confidence>\n",
    "        **Input**: {pid}  \n",
    "        **Output**:  \n",
    "        \"\"\"\n",
    "    \n",
    "    if prop == \"structure\":\n",
    "        prompt = f\"\"\" \n",
    "        **Instruction**:  \n",
    "        You are an information retrieval assistant. Given a Persistent Identifier (PID), determine the structure of the prefixes and identifier, using PID registry metadata and known PID system patterns. Choose from:  \n",
    "        1. **Allows User Semantics** (Identifier contains user-defined meaningful components)  \n",
    "        2. **Allows Managed Prefix** (Prefixes are assigned to different organizations)  \n",
    "        3. **No Prefix** (No namespace/prefix component)  \n",
    "        4. **Predefined Identifier Structure** (Fixed format with no user-defined components)  \n",
    "        5. **Unknown** (insufficient information)  \n",
    "\n",
    "        **Desired Format**:  \n",
    "        <PID>: <structure category>, <confidence>\n",
    "        **Input**: {pid}\n",
    "        **Output**:   \n",
    "        \"\"\"\n",
    "\n",
    "    if prop == \"governance\": \n",
    "\n",
    "        prompt = f\"\"\" \n",
    "         **Instruction**:  \n",
    "        You are an information retrieval assistant. Given a Persistent Identifier (PID), determine its governance mechanism using PID registry metadata and known PID system patterns. Choose from:  \n",
    "        1. **Community Governance** (open participation)  \n",
    "        2. **Membership Governance** (requires formal affiliation)  \n",
    "        3. **Closed Governance** (controlled by specific organization)  \n",
    "        4. **Unknown** (insufficient information)  \n",
    "\n",
    "        **Desired Format**:  \n",
    "        <PID>: <governance category>, <confidence>\n",
    "        **Input**: {pid}\n",
    "        **Output**: \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"sonar-pro\", \"llama-3.1-sonar-small-128k-online\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prop_types = [\"metadata\", \"structure\", \"governance\"]\n",
    "\n",
    "for model in models: \n",
    "    for pid in pids:\n",
    "        for prop_type in prop_types:\n",
    "            prompt = make_prompt(pid, prop_type)\n",
    "\n",
    "            answer, finish_reason, lodAIC = get_llm_response(prompt, model)\n",
    "            date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            prompt = prompt.replace('\\n', ' ').replace('\\r\\n', ' ')\n",
    "            \n",
    "            # Write to CSV\n",
    "            write_to_csv([lodAIC, model, prompt, answer, date, finish_reason], csv_filename)\n",
    "            #print(f\"Response for '{prompt}' has been written to {csv_filename}\")\n",
    "\n",
    "            #time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
